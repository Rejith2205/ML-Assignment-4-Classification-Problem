{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d4502c-cb0d-439d-9ae3-c4c320471846",
   "metadata": {},
   "source": [
    "# ***ML-Assignment-4-Classification Problem***  \n",
    "\n",
    "#      ***Breast-Cancer-Prediction***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d96968f-b82b-4e5e-9e02-665f9c4ee2e6",
   "metadata": {},
   "source": [
    "***Import Libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "d92a0f86-5950-42b9-806f-ea61418fc245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np#is a library for numerical computations\n",
    "import pandas as pd #A powerful library for data manipulation and analysis\n",
    "from sklearn.datasets import load_breast_cancer#his imports the breast cancer dataset from sklearn.datasets\n",
    "from sklearn.preprocessing import StandardScaler#This ensures all features are on a similar scale\n",
    "from sklearn.model_selection import train_test_split#Splits the dataset into training and testing subsets\n",
    "from sklearn.linear_model import LogisticRegression#a linear classifier for binary outcomes.\n",
    "from sklearn.tree import DecisionTreeClassifier# Which splits data based on feature thresholds to classify observations.\n",
    "from sklearn.ensemble import RandomForestClassifier#decision trees that improves accuracy and reduces overfitting.\n",
    "from sklearn.svm import SVC#Imports Support Vector Machine (SVM) with kernel functionality\n",
    "from sklearn.neighbors import KNeighborsClassifier#a simple and non-parametric classifier.\n",
    "#accuracy_score --Measures the overall accuracy of the model (correct predictions/total predictions).\n",
    "#classification_report--Provides a detailed summary of precision, recall, and F1-score for each class.\n",
    "#confusion_matrix---Evaluates performance by comparing actual vs. predicted labels in a matrix format\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1008aeed-ac76-4700-b950-be97350468a4",
   "metadata": {},
   "source": [
    "# ***1.\tLoading and Preprocessing*** \n",
    "\n",
    "***Loading and Preprocessing--\n",
    "Load the breast cancer dataset from sklearn using the load_breast_cancer function from sklearn***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "05a7f530-aff9-4b59-891c-4a38d5fdfb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "887f0d49-da4f-40f6-9412-82a3ea66ec6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "e1471711-d6a5-49c2-a8f7-77cf32c9dbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "e07ba07a-9926-4942-86c7-2c0a6087637d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information about the dimensions of the DataFrame, specifically the number of rows and columns.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "63921807-cd0d-42c4-8a60-68e56041aa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#to print the number of missing (NaN) values in each column of the DataFrame\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35bd971-c730-4ebb-b7e4-4ddcc13df5c5",
   "metadata": {},
   "source": [
    "***There is no missing values in the dataset,so need not imputation for this dataset.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "458a5b25-d21a-4bde-8caf-6eeaac5ca3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                float64\n",
       "mean texture               float64\n",
       "mean perimeter             float64\n",
       "mean area                  float64\n",
       "mean smoothness            float64\n",
       "mean compactness           float64\n",
       "mean concavity             float64\n",
       "mean concave points        float64\n",
       "mean symmetry              float64\n",
       "mean fractal dimension     float64\n",
       "radius error               float64\n",
       "texture error              float64\n",
       "perimeter error            float64\n",
       "area error                 float64\n",
       "smoothness error           float64\n",
       "compactness error          float64\n",
       "concavity error            float64\n",
       "concave points error       float64\n",
       "symmetry error             float64\n",
       "fractal dimension error    float64\n",
       "worst radius               float64\n",
       "worst texture              float64\n",
       "worst perimeter            float64\n",
       "worst area                 float64\n",
       "worst smoothness           float64\n",
       "worst compactness          float64\n",
       "worst concavity            float64\n",
       "worst concave points       float64\n",
       "worst symmetry             float64\n",
       "worst fractal dimension    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to print the number of missing (NaN) values in each column of the DataFrame\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123263e0-6fe7-413e-bf3b-6903824f6edd",
   "metadata": {},
   "source": [
    "***check the number of duplicate rows***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "67d32258-5033-4f88-8482-1ca62898d4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of  duplicate records found.\n",
      "No duplicate records found.\n"
     ]
    }
   ],
   "source": [
    "# to check the number of duplicate rows in the Dataframe\n",
    "duplicates_count = df.duplicated().sum()\n",
    "\n",
    "# Print the count of duplicate records\n",
    "if duplicates_count > 0:\n",
    "    print(f\"\\nNumber of duplicate records: {duplicates_count}\\n\")\n",
    "else:\n",
    "    print(\"Number of  duplicate records found.\")\n",
    "    \n",
    "# Check for duplicates\n",
    "duplicates = df[df.duplicated()]\n",
    "# Print duplicates with header and all data\n",
    "if not duplicates.empty:\n",
    "    print(duplicates.to_string(index=False))\n",
    "else:\n",
    "    print(\"No duplicate records found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "9e589e03-1ef9-4cd2-bf20-6faa87929aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
       "count     569.000000              569.000000  ...    569.000000   \n",
       "mean        0.181162                0.062798  ...     16.269190   \n",
       "std         0.027414                0.007060  ...      4.833242   \n",
       "min         0.106000                0.049960  ...      7.930000   \n",
       "25%         0.161900                0.057700  ...     13.010000   \n",
       "50%         0.179200                0.061540  ...     14.970000   \n",
       "75%         0.195700                0.066120  ...     18.790000   \n",
       "max         0.304000                0.097440  ...     36.040000   \n",
       "\n",
       "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       worst compactness  worst concavity  worst concave points  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       worst symmetry  worst fractal dimension  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21114c5-2441-4cde-8fab-6b86b27d89ec",
   "metadata": {},
   "source": [
    "# Breast cancer wisconsin (diagnostic) dataset\n",
    "\n",
    "\n",
    "**Data Set Characteristics:**\n",
    "\n",
    "***:Number of Instances: 569***\n",
    "\n",
    "***:Number of Attributes: 30 numeric, predictive attributes and the class***\n",
    "\n",
    "***:Attribute Information:\n",
    "    - radius (mean of distances from center to points on the perimeter)  \n",
    "    - texture (standard deviation of gray-scale values)  \n",
    "    - perimeter  \n",
    "    - area  \n",
    "    - smoothness (local variation in radius lengths)  \n",
    "    - compactness (perimeter^2 / area - 1.0)  \n",
    "    - concavity (severity of concave portions of the contour)  \n",
    "    - concave points (number of concave portions of the contour)  \n",
    "    - symmetry  \n",
    "    - fractal dimension (\"coastline approximation\" - 1)***  \n",
    "\n",
    "***The mean, standard error, and \"worst\" or largest (mean of the three\n",
    "    worst/largest values) of these features were computed for each image,\n",
    "    resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
    "    10 is Radius SE, field 20 is Worst Radius.***\n",
    "\n",
    "***- class:\n",
    "        - WDBC-Malignant  \n",
    "            - WDBC-Benign***   \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "***The above details are available by executing the code block \"print(cancer.DESCR)\"***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "b67d580d-fbde-4b70-9ba3-695419deba18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "a1d0598a-0e16-41f5-80f4-7406134c528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(cancer.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3febd6ce-8553-4c3c-a267-4fa99537a296",
   "metadata": {},
   "source": [
    "# ***2. Classification Algorithm Implementation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "6a43842a-1a4b-4ad1-9c04-05083a5e8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target for binary classification\n",
    "X = cancer.data  # Features\n",
    "y = cancer.target  # Target (binary class labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6965f5f-9c01-48a9-9c98-be50c9f948b8",
   "metadata": {},
   "source": [
    "***Standarize the feature***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "e87986b7-000e-4a05-9875-ce2b620947f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (455, 30)\n",
      "Test set size: (114, 30)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the sizes of the train and test sets\n",
    "print(\"Train set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab028cd-fdf8-4598-8c91-3e1963ed4724",
   "metadata": {},
   "source": [
    "# ***3. Logistic Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "1e876461-5b06-49b1-8101-ba5040e687f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9736842105263158\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[41  2]\n",
      " [ 1 70]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "clf_logistic_regression = LogisticRegression(max_iter=10000, random_state=42)\n",
    "clf_logistic_regression.fit(X_train, y_train)\n",
    "y_pred_logistic_regression = clf_logistic_regression.predict(X_test)\n",
    "accuracy_logistic_regression = accuracy_score(y_test, y_pred_logistic_regression)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logistic_regression}\")\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logistic_regression))\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_logistic_regression))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28983f5-758f-497a-bcb5-80e5bc924119",
   "metadata": {},
   "source": [
    "***The confusion matrix is a tool used to evaluate the performance of a classification model.***  \n",
    "***Confusion Matrix Analysis***  \n",
    "\n",
    "***considering  \n",
    "                0 as malignant cases  \n",
    "                1 as benign case***\n",
    "    \n",
    "    \n",
    "***41    2   ----  The model correctly predicted 41 malignant cases, the model incorrectly  predicted 2 bengin case as malignant***  \n",
    "***1     70  ----  The model incorrectly  predicted 1 benign case as malignant, the mode predicted 70 as benign case*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486558f-5054-4cfa-bbed-62abb693f160",
   "metadata": {},
   "source": [
    "***Logistic Regression  \n",
    "Logistic regression is a linear model that predicts the probability of a binary outcome (e.g., malignant or benign). It applies the sigmoid function to map predicted values to probabilities.  \n",
    "The breast cancer dataset is well-structured, and logistic regression performs well when the relationship between features and the target is mostly linear.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77366f-9d0f-4533-baf5-c444f0566cfc",
   "metadata": {},
   "source": [
    "# ***4.Decision Tree Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "c8b85f44-b0bd-450b-845b-21d43506542f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Accuracy: 0.9473684210526315\n",
      "Decision Tree Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        43\n",
      "           1       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Decision Tree Classifier Confusion Matrix:\n",
      "[[40  3]\n",
      " [ 3 68]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "clf_decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "clf_decision_tree.fit(X_train, y_train)\n",
    "y_pred_decision_tree = clf_decision_tree.predict(X_test)\n",
    "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
    "print(f\"Decision Tree Classifier Accuracy: {accuracy_decision_tree}\")\n",
    "print(\"Decision Tree Classifier Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_decision_tree))\n",
    "print(\"Decision Tree Classifier Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_decision_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45029aa-9646-4be0-b4f4-fcd457f91866",
   "metadata": {},
   "source": [
    "***Confusion Matrix Analysis***        \n",
    "***40    3   ----  The model correctly predicted 40 malignant cases, the model incorrectly  predicted 3 bengin case as malignant***  \n",
    "***3     68  ----  The model incorrectly  predicted 3 benign case as malignant, the mode predicted 68 as benign case*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd10c5e-2a6e-4a1a-a7cc-4284a7fa1513",
   "metadata": {},
   "source": [
    " ***Decision Tree Classifier***  \n",
    " ***Decision trees split the data into branches based on feature thresholds, creating a flowchart-like structure to classify observations.***\n",
    "\n",
    "***Decision trees can handle both linear and non-linear relationships, making them versatile for this dataset. They are also interpretable, which is valuable in medical diagnostics.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f001cd-9935-4657-bcf0-fcbdf8e0f279",
   "metadata": {},
   "source": [
    "# ***5. Random Forest Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "1394fb13-7c0f-4bad-b8a6-7cfe415a8b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.9649122807017544\n",
      "Random Forest Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "Random Forest Classifier Confusion Matrix:\n",
      "[[40  3]\n",
      " [ 1 70]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf_random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_random_forest.fit(X_train, y_train)\n",
    "y_pred_random_forest = clf_random_forest.predict(X_test)\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
    "print(f\"Random Forest Classifier Accuracy: {accuracy_random_forest}\")\n",
    "print(\"Random Forest Classifier Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_random_forest))\n",
    "print(\"Random Forest Classifier Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_random_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef98a8da-f952-4917-a1b0-cf1ceac4ce1f",
   "metadata": {},
   "source": [
    "***Confusion Matrix Analysis***    \n",
    "***40    3   ----  The model correctly predicted 40 malignant cases, the model incorrectly  predicted 3 bengin case as malignant***  \n",
    "***1     70  ----  The model incorrectly  predicted 1 benign case as malignant, the mode predicted 70 as benign case*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf2d7a0-acf3-46bb-abe8-7c92e122ff3b",
   "metadata": {},
   "source": [
    " ***Random Forest is an ensemble of decision trees. It builds multiple trees on random subsets of the data and aggregates their predictions (majority voting for classification).*** \n",
    "\n",
    "***This method reduces overfitting, which can occur with a single decision tree. It’s robust and often achieves high accuracy on structured datasets like this one.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f798b988-74f9-4b12-a33c-8e2f97ab56d9",
   "metadata": {},
   "source": [
    "# ***6. Support Vector Machine (SVM)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "994c6cab-c3e5-4f7e-8791-24624edc9572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9736842105263158\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "SVM Confusion Matrix:\n",
      "[[41  2]\n",
      " [ 1 70]]\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "clf_svm = SVC(random_state=42)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {accuracy_svm}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"SVM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f81ca1c-5766-4e99-91e0-060a2df58917",
   "metadata": {},
   "source": [
    "***Confusion Matrix Analysis***        \n",
    "***41    2   ----  The model correctly predicted 41 malignant cases, the model incorrectly  predicted 2 bengin case as malignant***  \n",
    "***1     70  ----  The model incorrectly  predicted 1 benign case as malignant, the mode predicted 70 as benign case*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48fb995-4ab3-46ec-9d7a-03d9b0a18905",
   "metadata": {},
   "source": [
    " ***SVM finds a hyperplane that best separates the data into two classes. For non-linearly separable data, it uses kernels (e.g., radial basis function) to map data to higher dimensions.***  \n",
    "***SVM works well on datasets with clear class boundaries and is effective for high-dimensional data, making it a strong choice for the 30-feature breast cancer dataset.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376d39c8-7c72-4e00-bc71-d678335b35b4",
   "metadata": {},
   "source": [
    "#  ***7. k-Nearest Neighbors (k-NN)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "f60cd072-7b5b-4a47-b60e-ad7009348dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Accuracy: 0.9473684210526315\n",
      "k-NN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        43\n",
      "           1       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "k-NN Confusion Matrix:\n",
      "[[40  3]\n",
      " [ 3 68]]\n"
     ]
    }
   ],
   "source": [
    "#k-Nearest Neighbors (k-NN)\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "clf_knn.fit(X_train, y_train)\n",
    "y_pred_knn = clf_knn.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"k-NN Accuracy: {accuracy_knn}\")\n",
    "print(\"k-NN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(\"k-NN Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c0fed-b9f1-4e4b-83e7-aecfdf3e291e",
   "metadata": {},
   "source": [
    "***Confusion Matrix Analysis***    \n",
    "***40    3   ----  The model correctly predicted 40 malignant cases, the model incorrectly  predicted 3 bengin case as malignant***  \n",
    "***3     68  ----  The model incorrectly  predicted 3 benign case as malignant, the mode predicted 68 as benign case*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52dd281-dbd4-4e0e-823f-5fa2c19fdae0",
   "metadata": {},
   "source": [
    "***k-Nearest Neighbors (k-NN)***  \n",
    "***k-NN classifies a data point based on the class of its k nearest neighbors in the feature space. It’s a non-parametric algorithm.***\n",
    "\n",
    "***k-NN is straightforward to implement and can perform well when the dataset is not too large (as in this case). It adapts naturally to non-linear decision boundaries.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8116467-dfeb-4767-a3be-852ffb84954f",
   "metadata": {},
   "source": [
    "# ***8. Compare the performance of the five classification algorithms. Which algorithm performed the best and which one performed the worst?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "24a41e77-807f-429f-bf68-bd7840c02cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best performing model is: LogisticRegression with an accuracy of 0.9737\n",
      "The worst performing model is: DecisionTreeClassifier with an accuracy of 0.9474\n"
     ]
    }
   ],
   "source": [
    "# Find the best and worst models based on accuracy\n",
    "best_model = max(results, key=lambda x: x['accuracy'])\n",
    "worst_model = min(results, key=lambda x: x['accuracy'])\n",
    "\n",
    "print(f\"The best performing model is: {best_model['model']} with an accuracy of {best_model['accuracy']:.4f}\")\n",
    "print(f\"The worst performing model is: {worst_model['model']} with an accuracy of {worst_model['accuracy']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
